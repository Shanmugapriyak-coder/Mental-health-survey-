{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c1ba878",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder,FunctionTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report,accuracy_score,precision_score,recall_score\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler \n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6f906f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "class CustomPreprocessor(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.nominal_data = ['Gender','Working Professional or Student','Profession','Degree','Sleep Duration','Dietary Habits']\n",
    "        self.allowed_profession = ['Teacher','Content Writer','Architect','Consultant','HR Manager','Pharmacist','Doctor','Business Analyst','Entrepreneur','Chemist']\n",
    "        self.allowed_sleepduration = ['Less than 5 hours','7-8 hours','More than 8 hours','5-6 hours','3-4 hours']\n",
    "        self.allowed_habits = ['Moderate','Unhealthy','Healthy']\n",
    "        self.allowed_degree = ['Class 12','B.Ed','B.Arch','B.Com','B.Pharm','BCA','M.Ed','MCA','BBA','BSc']\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        df = X.copy()\n",
    "        df.drop(['id','Name','City'], axis=1, inplace=True)\n",
    "\n",
    "        # Set academic values to 0 for professionals\n",
    "        df.loc[df['Working Professional or Student'] == 'Working Professional', ['CGPA', 'Academic Pressure', 'Study Satisfaction']] = 0.0\n",
    "\n",
    "        # Fill missing values\n",
    "        for col in ['Profession', 'Degree', 'Dietary Habits']:\n",
    "            df[col] = df[col].fillna(df[col].mode()[0])\n",
    "        for col in ['Work Pressure', 'Academic Pressure', 'Job Satisfaction', 'Financial Stress', 'CGPA', 'Study Satisfaction']:\n",
    "            df[col] = df[col].fillna(df[col].median())\n",
    "\n",
    "        # Map uncommon categories to 'Others'\n",
    "        df['Profession'] = df['Profession'].where(df['Profession'].isin(self.allowed_profession), 'Others')\n",
    "        df['Sleep Duration'] = df['Sleep Duration'].where(df['Sleep Duration'].isin(self.allowed_sleepduration), 'Others')\n",
    "        df['Dietary Habits'] = df['Dietary Habits'].where(df['Dietary Habits'].isin(self.allowed_habits), 'Others')\n",
    "        df['Degree'] = df['Degree'].where(df['Degree'].isin(self.allowed_degree), 'Others')\n",
    "\n",
    "        # Encode ordinal\n",
    "        df['Family History of Mental Illness'] = df['Family History of Mental Illness'].replace({'No': 0, 'Yes': 1})\n",
    "        df['Have you ever had suicidal thoughts ?'] = df['Have you ever had suicidal thoughts ?'].replace({'No': 0, 'Yes': 1})\n",
    "\n",
    "        # One-hot encoding\n",
    "        df = pd.get_dummies(df, columns=self.nominal_data, dtype='int')\n",
    "\n",
    "        # Handle outliers\n",
    "        for col in ['Academic Pressure','CGPA','Study Satisfaction']:\n",
    "            Q1 = df[col].quantile(0.25)\n",
    "            Q3 = df[col].quantile(0.75)\n",
    "            IQR = Q3 - Q1\n",
    "            lower = Q1 - 1.5 * IQR\n",
    "            upper = Q3 + 1.5 * IQR\n",
    "            df[col] = np.clip(df[col], lower, upper)\n",
    "\n",
    "        return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2935d6bf",
   "metadata": {},
   "source": [
    "# using custom class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c04d5adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "preprocessing_pipeline = Pipeline([\n",
    "    ('custom_preprocessor', CustomPreprocessor())\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27deec44",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MY Laptop\\AppData\\Local\\Temp\\ipykernel_7284\\420157920.py:36: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df['Family History of Mental Illness'] = df['Family History of Mental Illness'].replace({'No':0,'Yes':1})\n",
      "C:\\Users\\MY Laptop\\AppData\\Local\\Temp\\ipykernel_7284\\420157920.py:37: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df['Have you ever had suicidal thoughts ?'] = df['Have you ever had suicidal thoughts ?'].replace({'No':0,'Yes':1})\n"
     ]
    }
   ],
   "source": [
    "data=preprocessing_pipeline.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea3d5da",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DNN(nn.Module):\n",
    "    def __init__(self,input_size,hidden_size,output_size):\n",
    "        super(DNN,self).__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(input_size,hidden_size[0]),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size[0],hidden_size[1]),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size[1],hidden_size[2]),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size[2],hidden_size[3]),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size[3],output_size),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self,X):\n",
    "        X = self.layers(X)\n",
    "        return X\n",
    "model = DNN(input_size,hidden_size,output_size)\n",
    "criterion= nn.BCELoss()\n",
    "# optimizer = optim.SGD(model.parameters())\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e952c62e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MY Laptop\\AppData\\Local\\Temp\\ipykernel_7284\\4100365638.py:36: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df['Family History of Mental Illness'] = df['Family History of Mental Illness'].replace({'No': 0, 'Yes': 1})\n",
      "C:\\Users\\MY Laptop\\AppData\\Local\\Temp\\ipykernel_7284\\4100365638.py:37: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df['Have you ever had suicidal thoughts ?'] = df['Have you ever had suicidal thoughts ?'].replace({'No': 0, 'Yes': 1})\n",
      "C:\\Users\\MY Laptop\\AppData\\Local\\Temp\\ipykernel_7284\\4100365638.py:36: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df['Family History of Mental Illness'] = df['Family History of Mental Illness'].replace({'No': 0, 'Yes': 1})\n",
      "C:\\Users\\MY Laptop\\AppData\\Local\\Temp\\ipykernel_7284\\4100365638.py:37: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df['Have you ever had suicidal thoughts ?'] = df['Have you ever had suicidal thoughts ?'].replace({'No': 0, 'Yes': 1})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30, Loss: 0.1575\n",
      "Epoch 2/30, Loss: 0.2650\n",
      "Epoch 3/30, Loss: 0.2694\n",
      "Epoch 4/30, Loss: 0.1945\n",
      "Epoch 5/30, Loss: 0.0699\n",
      "Epoch 6/30, Loss: 0.0428\n",
      "Epoch 7/30, Loss: 0.1740\n",
      "Epoch 8/30, Loss: 0.5218\n",
      "Epoch 9/30, Loss: 0.1501\n",
      "Epoch 10/30, Loss: 0.0620\n",
      "Epoch 11/30, Loss: 0.0419\n",
      "Epoch 12/30, Loss: 0.0884\n",
      "Epoch 13/30, Loss: 0.1851\n",
      "Epoch 14/30, Loss: 0.0939\n",
      "Epoch 15/30, Loss: 0.1002\n",
      "Epoch 16/30, Loss: 0.1528\n",
      "Epoch 17/30, Loss: 0.0688\n",
      "Epoch 18/30, Loss: 0.0251\n",
      "Epoch 19/30, Loss: 0.5054\n",
      "Epoch 20/30, Loss: 0.1155\n",
      "Epoch 21/30, Loss: 0.0713\n",
      "Epoch 22/30, Loss: 0.0324\n",
      "Epoch 23/30, Loss: 0.0507\n",
      "Epoch 24/30, Loss: 0.4353\n",
      "Epoch 25/30, Loss: 0.1218\n",
      "Epoch 26/30, Loss: 0.1346\n",
      "Epoch 27/30, Loss: 0.0196\n",
      "Epoch 28/30, Loss: 0.2657\n",
      "Epoch 29/30, Loss: 0.1036\n",
      "Epoch 30/30, Loss: 0.0868\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.96      0.95     23027\n",
      "         1.0       0.82      0.75      0.78      5113\n",
      "\n",
      "    accuracy                           0.93     28140\n",
      "   macro avg       0.88      0.86      0.87     28140\n",
      "weighted avg       0.92      0.93      0.92     28140\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# Step 2: Read and split data\n",
    "df = pd.read_csv(r\"C:\\Users\\MY Laptop\\Desktop\\guvi_class\\mental health survey\\train.csv\")\n",
    "X = df.drop(['Depression'],axis=1)\n",
    "y = df['Depression']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 3: Preprocess\n",
    "# preprocessor = Pipeline([('preprocessor', FunctionTransformer(preprocessor))])\n",
    "X_train = preprocessing_pipeline.fit_transform(X_train)\n",
    "X_test = preprocessing_pipeline.transform(X_test)\n",
    "\n",
    "Step 4: SMOTE\n",
    "from imblearn.over_sampling import SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Step 5: Convert to torch tensors\n",
    "X_train_tensor = torch.tensor(X_train_res.values, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train_res.values.reshape(-1,1), dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test.values, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test.values.reshape(-1,1), dtype=torch.float32)\n",
    "\n",
    "# Step 6: Create DataLoader\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "# Step 7: Define your DNN model\n",
    "class DNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(DNN, self).__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(input_size, hidden_size[0]),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size[0], hidden_size[1]),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size[1], hidden_size[2]),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size[2], hidden_size[3]),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size[3], output_size),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, X):\n",
    "        return self.layers(X)\n",
    "\n",
    "input_size = X_train_tensor.shape[1]\n",
    "hidden_size = [32,16,8,4]\n",
    "output_size = 1\n",
    "\n",
    "model = DNN(input_size, hidden_size, output_size)\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# Step 8: Train the model\n",
    "num_epochs = 30\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(X_batch)\n",
    "        loss = criterion(y_pred, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {loss.item():.4f}\")\n",
    "\n",
    "# Step 9: Evaluate on test set\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y_pred_test = model(X_test_tensor)\n",
    "    y_pred_labels = (y_pred_test >= 0.5).float()\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test_tensor.numpy(), y_pred_labels.numpy()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3a8cfb36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ohe_columns.pkl']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ohe_columns\n",
    "joblib.dump(ohe_columns, 'ohe_columns.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d760e6d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'mental_health_dnn.pth')\n",
    "# To load later:\n",
    "# model.load_state_dict(torch.load('mental_health_dnn.pth'))\n",
    "# model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9cc4a903",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['preprocessor.pkl']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.dump(preprocessing_pipeline, 'preprocessor.pkl')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
